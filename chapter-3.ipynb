{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps with Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engineering involves crafting inputs to LLMs (prompts) that effectively communicate the task at hand to the LLM, leading it to return accurate and useful outputs (Figure 3.1). Prompt engineering is a skill that requires an understanding of the nuances of language, the specific domain being worked on, and the capabilities and limitations of the LLM being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing LLMs with Customized Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning hinges on the idea of transfer learning. Transfer learning is a technique that leverages pre-trained models to build upon existing knowledge for new tasks or domains. In the case of LLMs, this involves utilizing the pre-training to transfer general language understanding, including grammar and general knowledge, to particular domain-specific tasks. However, the pre-training may not be sufficient to understand the nuances of certain closed or specialized topics, such as a company’s legal structure or guidelines.\n",
    "\n",
    "### Fine-tuning is a specific form of transfer learning that adjusts the parameters of a pre-trained model to better suit a “downstream” target task. Through fine-tuning, LLMs can learn from custom examples and become more effective at generating relevant and accurate responses.\n",
    "\n",
    "\n",
    "### Training set: A collection of labeled examples used to train the model. The model learns to recognize patterns and relationships in the data by adjusting its parameters based on the training examples.\n",
    "\n",
    "### Validation set: A separate collection of labeled examples used to evaluate the model’s performance during training.\n",
    "\n",
    "### Test set: A third collection of labeled examples that is separate from both the training and validation sets. It is used to evaluate the final performance of the model after the training and fine-tuning processes are complete. The test set provides a final, unbiased estimate of the model’s ability to generalize to new, unseen data.\n",
    "\n",
    "### Loss function: A function that quantifies the difference between the model’s predictions and the actual target values. It serves as a metric of error to evaluate the model’s performance and guide the optimization process. During training, the goal is to minimize the loss function to achieve better predictions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
