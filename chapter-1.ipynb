{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive language models are trained to predict the next token in a sentence, based on only the previous tokens in the phrase. These models correspond to the decoder part of the Transformer model, with a mask being applied to the full sentence so that the attention heads can see only the tokens that came before. Autoregressive models are ideal for text generation. A good example of this type of model is GPT.\n",
    "\n",
    "### Autoencoding language models are trained to reconstruct the original sentence from a corrupted version of the input. These models correspond to the encoder part of the Transformer model and have access to the full input without any mask. Autoencoding models create a bidirectional representation of the whole sentence. They can be fine-tuned for a variety of tasks such as text generation, but their main application is sentence classification or token classification. A typical example of this type of model is BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Characteristics of LLMs\n",
    "\n",
    "### The original Transformer architecture, as devised in 2017, was a sequence-to-sequence model, which means it had two main components:\n",
    "\n",
    "### An encoder, which is tasked with taking in raw text, splitting it up into its core components (more on this later), converting those components into vectors (similar to the Word2vec process), and using attention to understand the context of the text\n",
    "\n",
    "### A decoder, which excels at generating text by using a modified type of attention to predict the next best token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "### Once an LLM has been pre-trained, it can be fine-tuned for specific tasks. Fine-tuning involves training the LLM on a smaller, task-specific dataset to adjust its parameters for the specific task at hand. This allows the LLM to leverage its pre-trained knowledge of the language to improve its accuracy for the specific task. Fine-tuning has been shown to drastically improve performance on domain-specific and task-specific tasks and lets LLMs adapt quickly to a wide variety of NLP applications.\n",
    "\n",
    "We define the model we want to fine-tune as well as any fine-tuning parameters (e.g., learning rate).\n",
    "\n",
    "We aggregate some training data (the format and other characteristics depend on the model we are updating).\n",
    "\n",
    "We compute losses (a measure of error) and gradients (information about how to change the model to minimize error).\n",
    "\n",
    "We update the model through backpropagation—a mechanism to update model parameters to minimize errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "### The title of the original paper that introduced the Transformer was “Attention Is All You Need.” Attention is a mechanism used in deep learning models (not just Transformers) that assigns different weights to different parts of the input, allowing the model to prioritize and emphasize the most important information while performing tasks like translation or summarization. Essentially, attention allows a model to “focus” on different parts of the input dynamically, leading to improved performance and more accurate results. Before the popularization of attention, most neural networks processed all inputs equally and the models relied on a fixed representation of the input to make predictions. Modern LLMs that rely on attention can dynamically focus on different parts of input sequences, allowing them to weigh the importance of each part in making predictions.\n",
    "\n",
    "### LLMs are pre-trained on large corpora and sometimes fine-tuned on smaller datasets for specific tasks. Recall that one of the factors behind the Transformer’s effectiveness as a language model is that it is highly parallelizable, allowing for faster training and efficient processing of text. What really sets the Transformer apart from other deep learning architectures is its ability to capture long-range dependencies and relationships between tokens using attention. In other words, attention is a crucial component of Transformer-based LLMs, and it enables them to effectively retain information between training loops and tasks (i.e., transfer learning), while being able to process lengthy swatches of text with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "### For any LLM to learn any kind of rule, however, it has to convert what we perceive as text into something machine readable. This is done through the process of embedding.\n",
    "\n",
    "### Embeddings are the mathematical representations of words, phrases, or tokens in a large-dimensional space. In NLP, embeddings are used to represent the words, phrases, or tokens in a way that captures their semantic meaning and relationships with other words. Several types of embeddings are possible, including position embeddings, which encode the position of a token in a sentence, and token embeddings, which encode the semantic meaning of a token.\n",
    "\n",
    "### LLMs learn different embeddings for tokens based on their pre-training and can further update these embeddings during fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Tokenization, as mentioned previously, involves breaking text down into the smallest unit of understanding—tokens. These tokens are the pieces of information that are embedded into semantic meaning and act as inputs to the attention calculations, which leads to . . . well, the LLM actually learning and working. Tokens make up an LLM’s static vocabulary and don’t always represent entire words. For example, tokens can represent punctuation, individual characters, or even a sub-word if a word is not known to the LLM. Nearly all LLMs also have special tokens that have specific meaning to the model. For example, the BERT model has the special [CLS] token, which BERT automatically injects as the first token of every input and is meant to represent an encoded semantic meaning for the entire input sequence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
